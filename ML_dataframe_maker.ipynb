{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fcfcbc-f6af-4a00-be5d-c4a9b42529d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 16:46:09.865 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.866 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.867 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.868 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.868 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.869 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.869 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.870 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.870 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.871 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.872 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.873 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-04-16 16:46:09.874 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "from data_loader import find_common_dates_from_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73633f96-6fb4-43bc-9d6e-6914637204f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2022-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2022-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2022-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2022-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2022-10-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date\n",
       "0    2010-01-02\n",
       "1    2010-01-03\n",
       "2    2010-01-04\n",
       "3    2010-01-05\n",
       "4    2010-01-06\n",
       "..          ...\n",
       "665  2022-10-26\n",
       "666  2022-10-27\n",
       "667  2022-10-28\n",
       "668  2022-10-29\n",
       "669  2022-10-30\n",
       "\n",
       "[670 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.DataFrame({'date':find_common_dates_from_datasets()})\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd111f3-4e23-4cdd-8245-6f4adba86430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions for formatting data sets\n",
    "\n",
    "def lon_to_longitude(df):\n",
    "    '''\n",
    "    Simple function to add latitude and longitude columns if dataframe only contains columns labeled lon and lat\n",
    "    '''\n",
    "    if 'lon' in df.columns:\n",
    "        df['longitude'] = df['lon']\n",
    "        df.drop('lon', axis = 1, inplace = True)\n",
    "    \n",
    "    if 'lat' in df.columns:\n",
    "        df['latitude'] = df['lat']\n",
    "        df.drop('lat', axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "def mv_rounder(df, feature = 'none', date = 'none'):\n",
    "    '''\n",
    "    Simple function to round latitude and longitude to nearest 0.5, and drop duplicates (averaging value in feature between duplicates).\n",
    "    Note that latitude and longitude columns must be named 'latitude' and 'longitude' not 'lat' and 'lon'.\n",
    "\n",
    "    inputs:\n",
    "\n",
    "    df (Pandas DataFrame) - dataframe to be used\n",
    "    feature (column name) - if set, feature to average when duplicates dropped\n",
    "    data (column name) - if set, date column to be used for dropping duplicates\n",
    "    '''\n",
    "\n",
    "    if ('latitude' and 'longitude') in df.columns:\n",
    "        df['longitude'] = df['longitude'].apply(lambda x: round(x/0.5) * 0.5).apply(lambda x: round(x,1))\n",
    "        df['latitude'] = df['latitude'].apply(lambda x: round(x/0.5) * 0.5).apply(lambda x: round(x,1))\n",
    "\n",
    "        if date == 'none':\n",
    "            if feature != 'none':\n",
    "                df = df.groupby(['latitude', 'longitude']).agg({feature: 'mean'}).reset_index()\n",
    "            else:\n",
    "                df.drop_duplicates(subset = ['latitude','longitude'], inplace = True)\n",
    "\n",
    "        else:\n",
    "            if feature != 'none':\n",
    "                df = df.groupby(['latitude', 'longitude', date]).agg({feature: 'mean'}).reset_index()\n",
    "            else:\n",
    "                df.drop_duplicates(subset = ['latitude','longitude', date], inplace = True)           \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a03f93-35d9-46a6-8a75-5a5b71857916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import fire data\n",
    "\n",
    "# CSV file names\n",
    "fire_folder_path = './USA_fire_date_2010_2023'\n",
    "csv_fire_files = [file for file in os.listdir(fire_folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and create a dataframe for said file, restricting to rough california coordinates\n",
    "fire_dataframes = {}\n",
    "for csv_file in csv_fire_files:\n",
    "\n",
    "    year = int(csv_file.split('_')[2].split('.')[0])\n",
    "    \n",
    "    fire_df = pd.read_csv(os.path.join(fire_folder_path, csv_file), usecols = ['latitude','longitude','acq_date'])\n",
    "    mv_rounder(fire_df, date = 'acq_date')\n",
    "    fire_df.rename(columns = {'acq_date':'date'}, inplace = True)\n",
    "    fire_df['fire'] = [1]*len(fire_df)\n",
    "    \n",
    "    \n",
    "    fire_dataframes[f'{year}'] = fire_df\n",
    "\n",
    "fire_all_data = pd.concat(fire_dataframes, ignore_index = True)\n",
    "fire_2015 = fire_dataframes['2015']\n",
    "fire_2015['month'] = fire_2015['date'].apply(lambda x: x[5:7])\n",
    "len(fire_2015[fire_2015['month'] == '08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c363144-f39e-4174-895a-6a45237e83bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qair_f_inst</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005590</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004197</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004090</td>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003755</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006247</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2010-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380242</th>\n",
       "      <td>0.005064</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380243</th>\n",
       "      <td>0.004874</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380244</th>\n",
       "      <td>0.005794</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380245</th>\n",
       "      <td>0.005263</td>\n",
       "      <td>-122.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380246</th>\n",
       "      <td>0.004982</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380247 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Qair_f_inst  longitude  latitude        date\n",
       "0          0.005590     -117.0      33.0  2010-05-01\n",
       "1          0.004197     -116.0      33.0  2010-05-01\n",
       "2          0.004090     -115.5      33.0  2010-05-01\n",
       "3          0.003755     -115.0      33.0  2010-05-01\n",
       "4          0.006247     -117.5      33.5  2010-05-01\n",
       "...             ...        ...       ...         ...\n",
       "380242     0.005064     -120.5      41.5  2010-05-18\n",
       "380243     0.004874     -120.0      41.5  2010-05-18\n",
       "380244     0.005794     -123.0      42.0  2010-05-18\n",
       "380245     0.005263     -122.5      42.0  2010-05-18\n",
       "380246     0.004982     -122.0      42.0  2010-05-18\n",
       "\n",
       "[380247 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import humidity data\n",
    "\n",
    "# CSV file names\n",
    "humidity_folder_path = './humidity_data/processed_data'\n",
    "csv_humidity_files = [file for file in os.listdir(humidity_folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and create a dataframe for said file, restricting to rough california coordinates\n",
    "humidity_dataframes = {}\n",
    "for csv_file in csv_humidity_files:\n",
    "\n",
    "    day = csv_file.split('.')[0]\n",
    "    \n",
    "    humidity_df = pd.read_csv(os.path.join(humidity_folder_path, csv_file))\n",
    "    \n",
    "    lon_to_longitude(humidity_df)\n",
    "    mv_rounder(humidity_df)\n",
    "    humidity_df = humidity_df[humidity_df['Qair_f_inst'] != 0.0]\n",
    "    humidity_df['date'] = [day]*len(humidity_df)\n",
    "    humidity_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    \n",
    "    humidity_dataframes[f'{day}'] = humidity_df\n",
    "\n",
    "humidity_dataframes['2015-08-11']\n",
    "humidity_all_data = pd.concat(humidity_dataframes, ignore_index=True)\n",
    "humidity_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e119f604-ece4-4802-ad89-bd4ece64f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgSurfT_tavg</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-252.23542</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-247.22337</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-242.25870</td>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-242.66176</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-253.22930</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582136</th>\n",
       "      <td>5.37090</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582137</th>\n",
       "      <td>4.98100</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582138</th>\n",
       "      <td>7.10790</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582139</th>\n",
       "      <td>7.08470</td>\n",
       "      <td>-122.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582140</th>\n",
       "      <td>6.21386</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582141 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AvgSurfT_tavg  longitude  latitude        date\n",
       "0          -252.23542     -117.0      33.0  2018-09-19\n",
       "1          -247.22337     -116.0      33.0  2018-09-19\n",
       "2          -242.25870     -115.5      33.0  2018-09-19\n",
       "3          -242.66176     -115.0      33.0  2018-09-19\n",
       "4          -253.22930     -117.5      33.5  2018-09-19\n",
       "...               ...        ...       ...         ...\n",
       "582136        5.37090     -120.5      41.5  2010-05-18\n",
       "582137        4.98100     -120.0      41.5  2010-05-18\n",
       "582138        7.10790     -123.0      42.0  2010-05-18\n",
       "582139        7.08470     -122.5      42.0  2010-05-18\n",
       "582140        6.21386     -122.0      42.0  2010-05-18\n",
       "\n",
       "[582141 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import temperature data\n",
    "\n",
    "# CSV file names\n",
    "temperature_folder_path = './temperature_data/processed'\n",
    "csv_temperature_files = [file for file in os.listdir(temperature_folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and create a dataframe for said file, restricting to rough california coordinates\n",
    "temperature_dataframes = {}\n",
    "for csv_file in csv_temperature_files:\n",
    "\n",
    "    day = csv_file.split('.')[0]\n",
    "    \n",
    "    temperature_df = pd.read_csv(os.path.join(temperature_folder_path, csv_file)) #,index_col = 'index')\n",
    "    \n",
    "    lon_to_longitude(temperature_df)\n",
    "    mv_rounder(temperature_df)\n",
    "    temperature_df = temperature_df.dropna()\n",
    "    temperature_df['date'] = [day]*len(temperature_df)\n",
    "    temperature_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    temperature_df.rename(columns = {'time':'date'}, inplace = True)\n",
    "    \n",
    "    temperature_dataframes[f'{day}'] = temperature_df\n",
    "\n",
    "temperature_all_data = pd.concat(temperature_dataframes, ignore_index=True)\n",
    "temperature_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cada1b2-6a65-424e-87fe-b20e6143bf31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPEEDLML</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.745177</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.861616</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.926813</td>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.420054</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.574027</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2018-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556467</th>\n",
       "      <td>6.044104</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556468</th>\n",
       "      <td>6.158571</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556469</th>\n",
       "      <td>3.761051</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556470</th>\n",
       "      <td>3.553320</td>\n",
       "      <td>-122.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556471</th>\n",
       "      <td>5.052917</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2010-05-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556472 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SPEEDLML  longitude  latitude        date\n",
       "0       4.745177     -117.0      33.0  2018-09-19\n",
       "1       6.861616     -116.0      33.0  2018-09-19\n",
       "2       4.926813     -115.5      33.0  2018-09-19\n",
       "3       4.420054     -115.0      33.0  2018-09-19\n",
       "4       3.574027     -117.5      33.5  2018-09-19\n",
       "...          ...        ...       ...         ...\n",
       "556467  6.044104     -120.5      41.5  2010-05-18\n",
       "556468  6.158571     -120.0      41.5  2010-05-18\n",
       "556469  3.761051     -123.0      42.0  2010-05-18\n",
       "556470  3.553320     -122.5      42.0  2010-05-18\n",
       "556471  5.052917     -122.0      42.0  2010-05-18\n",
       "\n",
       "[556472 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import wind data\n",
    "\n",
    "# CSV file names\n",
    "wind_folder_path = './wind_data/wind_data/csv/daily'\n",
    "csv_wind_files = [file for file in os.listdir(wind_folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file and create a dataframe for said file, restricting to rough california coordinates\n",
    "wind_dataframes = {}\n",
    "for csv_file in csv_wind_files:\n",
    "\n",
    "    day = csv_file.split('.')[0]\n",
    "    \n",
    "    wind_df = pd.read_csv(os.path.join(wind_folder_path, csv_file), usecols = ['SPEEDLML','lon','lat'])\n",
    "    \n",
    "    lon_to_longitude(wind_df)\n",
    "    mv_rounder(wind_df)\n",
    "    wind_df = wind_df[wind_df['SPEEDLML'] != 0]\n",
    "    wind_df['date'] = [day]*len(wind_df)\n",
    "    \n",
    "    wind_dataframes[f'{day}'] = wind_df\n",
    "\n",
    "wind_dataframes['2015-08-11']\n",
    "wind_all_data = pd.concat(wind_dataframes, ignore_index=True)\n",
    "wind_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e3fd559-b46e-4de9-8f70-660cd6a3e6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitationCal</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.298932</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186110</td>\n",
       "      <td>-116.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272104</td>\n",
       "      <td>-118.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007401</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059209</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2015-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>0.343548</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2015-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10560</th>\n",
       "      <td>0.013281</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2015-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>0.041836</td>\n",
       "      <td>-121.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2015-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10562</th>\n",
       "      <td>0.013478</td>\n",
       "      <td>-121.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2015-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>0.078881</td>\n",
       "      <td>-121.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2015-09-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10564 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       precipitationCal  longitude  latitude        date\n",
       "0              1.298932     -119.0      34.5  2015-09-26\n",
       "1              0.186110     -116.5      34.5  2015-09-26\n",
       "2              0.272104     -118.5      35.0  2015-09-26\n",
       "3              0.007401     -118.0      35.0  2015-09-26\n",
       "4              0.059209     -117.5      35.0  2015-09-26\n",
       "...                 ...        ...       ...         ...\n",
       "10559          0.343548     -120.5      41.0  2015-09-03\n",
       "10560          0.013281     -123.0      41.5  2015-09-03\n",
       "10561          0.041836     -121.5      41.5  2015-09-03\n",
       "10562          0.013478     -121.5      42.0  2015-09-03\n",
       "10563          0.078881     -121.0      42.0  2015-09-03\n",
       "\n",
       "[10564 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import precipitation data\n",
    "\n",
    "# CSV file names\n",
    "precipitation_folder_path = './precipitation_data/.csv/daily'\n",
    "csv_precipitation_files = [file for file in os.listdir(precipitation_folder_path) if (file.endswith('.csv') and file.startswith('2015'))]\n",
    "\n",
    "# Loop through each CSV file and create a dataframe for said file, restricting to rough california coordinates\n",
    "precipitation_dataframes = {}\n",
    "for csv_file in csv_precipitation_files:\n",
    "\n",
    "    day = csv_file.split('.')[0]\n",
    "    \n",
    "    precipitation_df = pd.read_csv(os.path.join(precipitation_folder_path, csv_file), usecols = ['precipitationCal','lon','lat'])\n",
    "    \n",
    "    lon_to_longitude(precipitation_df)\n",
    "    mv_rounder(precipitation_df)\n",
    "    precipitation_df = precipitation_df[precipitation_df['precipitationCal'] != 0]\n",
    "    precipitation_df['date'] = [day]*len(precipitation_df)\n",
    "    \n",
    "    precipitation_dataframes[f'{day}'] = precipitation_df\n",
    "\n",
    "precipitation_all_data = pd.concat(precipitation_dataframes, ignore_index=True)\n",
    "precipitation_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9be7b5e-4e87-4f2a-b05a-62ea568a97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116.0\n",
      "26690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humidity</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002801</td>\n",
       "      <td>-117.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>16.02690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.324515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002490</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>14.43972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.492439</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002753</td>\n",
       "      <td>-115.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>16.33618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.186181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>14.00012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.194674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003392</td>\n",
       "      <td>-117.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>18.03130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.882323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89105</th>\n",
       "      <td>0.003189</td>\n",
       "      <td>-120.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>9.81548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89106</th>\n",
       "      <td>0.003177</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>9.12050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.359795</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>0.005613</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>9.70107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.106233</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89108</th>\n",
       "      <td>0.005114</td>\n",
       "      <td>-122.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>9.26983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.280401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89109</th>\n",
       "      <td>0.004616</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>9.15612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.311043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89110 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       humidity  longitude  latitude        date  temperature  precipitation  \\\n",
       "0      0.002801     -117.0      33.0  2010-01-02     16.02690            0.0   \n",
       "1      0.002490     -116.0      33.0  2010-01-02     14.43972            0.0   \n",
       "2      0.002753     -115.5      33.0  2010-01-02     16.33618            0.0   \n",
       "3      0.002701     -115.0      33.0  2010-01-02     14.00012            0.0   \n",
       "4      0.003392     -117.5      33.5  2010-01-02     18.03130            0.0   \n",
       "...         ...        ...       ...         ...          ...            ...   \n",
       "89105  0.003189     -120.5      41.5  2022-10-30      9.81548            0.0   \n",
       "89106  0.003177     -120.0      41.5  2022-10-30      9.12050            0.0   \n",
       "89107  0.005613     -123.0      42.0  2022-10-30      9.70107            0.0   \n",
       "89108  0.005114     -122.5      42.0  2022-10-30      9.26983            0.0   \n",
       "89109  0.004616     -122.0      42.0  2022-10-30      9.15612            0.0   \n",
       "\n",
       "       wind_speed  fire  \n",
       "0        5.324515   0.0  \n",
       "1        3.492439   0.0  \n",
       "2        5.186181   0.0  \n",
       "3        7.194674   0.0  \n",
       "4        4.882323   0.0  \n",
       "...           ...   ...  \n",
       "89105    2.130499   0.0  \n",
       "89106    1.359795   0.0  \n",
       "89107    2.106233   0.0  \n",
       "89108    2.280401   0.0  \n",
       "89109    2.311043   0.0  \n",
       "\n",
       "[89110 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframes into one\n",
    "\n",
    "# Precipitaion merge on left as otherwise it creates extra fire events, fire merge on left to preserve points of no fire\n",
    "df_total = pd.merge(humidity_all_data, temperature_all_data, on=['latitude', 'longitude','date'], how = 'outer')\n",
    "df_total = pd.merge(df_total,precipitation_all_data, on=['latitude', 'longitude','date'], how = 'left')\n",
    "df_total = pd.merge(df_total,wind_all_data, on=['latitude', 'longitude','date'], how = 'outer')\n",
    "df_total = pd.merge(df_total,dates, on = ['date'], how = 'right') #ensures only common dates to all features done\n",
    "df_total = pd.merge(df_total, fire_all_data, on=['latitude', 'longitude','date'], how = 'left')\n",
    "\n",
    "df_total.rename(columns = {'Qair_f_inst':'humidity', 'AvgSurfT_tavg':'temperature', 'precipitationCal':'precipitation', 'SPEEDLML':'wind_speed'}, inplace = True)\n",
    "\n",
    "df_total.replace(np.nan,0, inplace = True)\n",
    "df_total.drop_duplicates(subset = ['latitude','longitude', 'date'], inplace = True)\n",
    "#df_total.drop('month', axis = 1, inplace = True)\n",
    "\n",
    "print(sum(df_total['fire']))\n",
    "print(len(fire_all_data))\n",
    "#print(len(fire_2015[fire_2015['month'] == '08']))\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25a5351f-ed72-4ec4-82cf-7e5975fb077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2010-01-02', '2010-01-03', '2010-01-04', '2010-01-05',\n",
       "       '2010-01-06', '2010-01-07', '2010-01-08', '2010-01-09',\n",
       "       '2010-01-10', '2010-01-11', '2010-01-12', '2010-01-13',\n",
       "       '2010-01-14', '2010-01-15', '2010-01-16', '2010-01-17',\n",
       "       '2010-01-18', '2010-01-19', '2010-01-20', '2010-01-21',\n",
       "       '2010-01-22', '2010-01-23', '2010-01-24', '2010-01-25',\n",
       "       '2010-01-26', '2010-01-27', '2010-01-28', '2010-01-29',\n",
       "       '2010-01-30', '2010-01-31', '2010-03-01', '2010-03-02',\n",
       "       '2010-03-03', '2010-03-04', '2010-03-05', '2010-03-06',\n",
       "       '2010-03-07', '2010-03-08', '2010-03-09', '2010-03-10',\n",
       "       '2010-03-11', '2010-03-12', '2010-03-13', '2010-03-14',\n",
       "       '2010-03-15', '2010-03-16', '2010-03-17', '2010-03-18',\n",
       "       '2010-03-19', '2010-03-20', '2010-03-21', '2010-03-22',\n",
       "       '2010-03-23', '2010-03-24', '2010-03-25', '2010-03-26',\n",
       "       '2010-03-27', '2010-03-28', '2010-03-29', '2010-03-30',\n",
       "       '2010-03-31', '2010-04-01', '2010-04-02', '2010-04-03',\n",
       "       '2010-04-04', '2010-04-05', '2010-04-06', '2010-04-07',\n",
       "       '2010-04-08', '2010-04-09', '2010-04-10', '2010-04-11',\n",
       "       '2010-04-12', '2010-04-13', '2010-04-14', '2010-04-15',\n",
       "       '2010-04-16', '2010-04-17', '2010-04-18', '2010-04-19',\n",
       "       '2010-04-20', '2010-04-21', '2010-04-22', '2010-04-23',\n",
       "       '2010-04-24', '2010-04-25', '2010-04-26', '2010-04-27',\n",
       "       '2010-04-28', '2010-04-29', '2010-04-30', '2010-05-01',\n",
       "       '2010-05-02', '2010-05-03', '2010-05-04', '2010-05-05',\n",
       "       '2010-05-06', '2010-05-07', '2010-05-08', '2010-05-09',\n",
       "       '2010-05-10', '2010-05-11', '2010-05-12', '2010-05-13',\n",
       "       '2010-05-14', '2010-05-15', '2010-05-16', '2010-05-17',\n",
       "       '2010-05-18', '2010-05-19', '2010-05-20', '2010-05-21',\n",
       "       '2010-05-22', '2010-05-23', '2010-05-24', '2010-05-25',\n",
       "       '2010-05-26', '2010-05-27', '2010-05-28', '2010-05-29',\n",
       "       '2010-05-30', '2010-05-31', '2010-06-01', '2010-06-02',\n",
       "       '2010-06-03', '2010-06-04', '2010-06-05', '2010-06-06',\n",
       "       '2010-06-07', '2010-06-08', '2010-06-09', '2010-06-10',\n",
       "       '2010-06-11', '2010-06-12', '2010-06-13', '2010-06-14',\n",
       "       '2010-06-15', '2010-06-16', '2010-06-17', '2010-06-18',\n",
       "       '2010-06-19', '2010-06-20', '2010-06-21', '2010-06-22',\n",
       "       '2010-06-23', '2010-06-24', '2010-06-25', '2010-06-26',\n",
       "       '2010-06-27', '2010-06-28', '2010-06-29', '2010-06-30',\n",
       "       '2010-07-01', '2010-07-02', '2010-07-03', '2010-07-04',\n",
       "       '2010-07-05', '2010-07-06', '2010-07-07', '2010-07-08',\n",
       "       '2010-07-09', '2010-07-10', '2010-07-11', '2010-07-12',\n",
       "       '2010-07-13', '2010-07-14', '2010-07-15', '2010-07-16',\n",
       "       '2010-07-17', '2010-07-18', '2010-07-19', '2010-07-20',\n",
       "       '2010-07-21', '2010-07-22', '2010-07-23', '2010-07-24',\n",
       "       '2010-07-25', '2010-07-26', '2010-07-27', '2010-07-28',\n",
       "       '2010-07-29', '2010-07-30', '2010-07-31', '2010-08-01',\n",
       "       '2010-08-02', '2010-08-03', '2010-08-04', '2010-08-05',\n",
       "       '2010-08-06', '2010-08-07', '2010-08-08', '2010-08-09',\n",
       "       '2010-08-10', '2010-08-11', '2010-08-12', '2010-08-13',\n",
       "       '2010-08-14', '2010-08-15', '2010-08-16', '2010-08-17',\n",
       "       '2010-08-18', '2010-08-19', '2010-08-20', '2010-08-21',\n",
       "       '2010-08-22', '2010-08-23', '2010-08-24', '2010-08-25',\n",
       "       '2010-08-26', '2010-08-27', '2010-08-28', '2010-08-29',\n",
       "       '2010-08-30', '2010-08-31', '2010-09-01', '2010-09-02',\n",
       "       '2010-09-03', '2010-09-04', '2010-09-05', '2010-09-06',\n",
       "       '2010-09-07', '2010-09-08', '2010-09-09', '2010-09-10',\n",
       "       '2010-09-11', '2010-09-12', '2010-09-13', '2010-09-14',\n",
       "       '2010-09-15', '2010-09-16', '2010-09-17', '2010-09-18',\n",
       "       '2010-09-19', '2010-09-20', '2010-09-21', '2010-09-22',\n",
       "       '2010-09-23', '2010-09-24', '2010-09-25', '2010-09-26',\n",
       "       '2010-09-27', '2010-09-28', '2010-09-29', '2010-09-30',\n",
       "       '2010-10-01', '2010-10-02', '2010-10-03', '2010-10-04',\n",
       "       '2010-10-05', '2010-10-06', '2010-10-07', '2010-10-08',\n",
       "       '2010-10-09', '2010-10-10', '2010-10-11', '2010-10-12',\n",
       "       '2010-10-13', '2010-10-14', '2010-10-15', '2010-10-16',\n",
       "       '2010-10-17', '2010-10-18', '2010-10-19', '2010-10-20',\n",
       "       '2010-10-21', '2010-10-22', '2010-10-23', '2010-10-24',\n",
       "       '2010-10-25', '2010-10-26', '2010-10-27', '2010-10-28',\n",
       "       '2010-10-29', '2010-10-30', '2010-10-31', '2010-11-01',\n",
       "       '2010-11-02', '2010-11-03', '2010-11-04', '2010-11-05',\n",
       "       '2010-11-06', '2010-11-07', '2010-11-08', '2010-11-09',\n",
       "       '2010-11-10', '2010-11-11', '2010-11-12', '2010-11-13',\n",
       "       '2010-11-14', '2010-11-15', '2010-11-16', '2010-11-17',\n",
       "       '2010-11-18', '2010-11-19', '2010-11-20', '2010-11-21',\n",
       "       '2010-11-22', '2010-11-23', '2010-11-24', '2010-11-25',\n",
       "       '2010-11-26', '2010-11-27', '2010-11-28', '2010-11-29',\n",
       "       '2010-11-30', '2010-12-01', '2010-12-02', '2010-12-03',\n",
       "       '2010-12-04', '2010-12-05', '2010-12-06', '2010-12-07',\n",
       "       '2010-12-08', '2010-12-09', '2010-12-10', '2010-12-11',\n",
       "       '2010-12-12', '2010-12-13', '2010-12-14', '2010-12-15',\n",
       "       '2010-12-16', '2010-12-17', '2010-12-18', '2010-12-19',\n",
       "       '2010-12-20', '2010-12-21', '2010-12-22', '2010-12-23',\n",
       "       '2010-12-24', '2010-12-25', '2010-12-26', '2010-12-27',\n",
       "       '2010-12-28', '2010-12-29', '2010-12-30', '2010-12-31',\n",
       "       '2015-08-01', '2015-08-02', '2015-08-03', '2015-08-04',\n",
       "       '2015-08-05', '2015-08-06', '2015-08-07', '2015-08-08',\n",
       "       '2015-08-09', '2015-08-10', '2015-08-11', '2015-08-12',\n",
       "       '2015-08-13', '2015-08-14', '2015-08-15', '2015-08-16',\n",
       "       '2015-08-17', '2015-08-18', '2015-08-19', '2015-08-20',\n",
       "       '2015-08-21', '2015-08-22', '2015-08-23', '2015-08-24',\n",
       "       '2015-08-25', '2015-08-26', '2015-08-27', '2015-08-28',\n",
       "       '2015-08-29', '2015-08-30', '2015-08-31', '2022-01-01',\n",
       "       '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05',\n",
       "       '2022-01-06', '2022-01-07', '2022-01-08', '2022-01-09',\n",
       "       '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13',\n",
       "       '2022-01-14', '2022-01-15', '2022-01-16', '2022-01-17',\n",
       "       '2022-01-18', '2022-01-19', '2022-01-20', '2022-01-21',\n",
       "       '2022-01-22', '2022-01-23', '2022-01-24', '2022-01-25',\n",
       "       '2022-01-26', '2022-01-27', '2022-01-28', '2022-01-29',\n",
       "       '2022-01-30', '2022-01-31', '2022-02-01', '2022-02-02',\n",
       "       '2022-02-03', '2022-02-04', '2022-02-05', '2022-02-06',\n",
       "       '2022-02-07', '2022-02-08', '2022-02-09', '2022-02-10',\n",
       "       '2022-02-11', '2022-02-12', '2022-02-13', '2022-02-14',\n",
       "       '2022-02-15', '2022-02-16', '2022-02-17', '2022-02-18',\n",
       "       '2022-02-19', '2022-02-20', '2022-02-21', '2022-02-22',\n",
       "       '2022-02-23', '2022-02-24', '2022-02-25', '2022-02-26',\n",
       "       '2022-02-27', '2022-02-28', '2022-03-01', '2022-03-02',\n",
       "       '2022-03-03', '2022-03-04', '2022-03-05', '2022-03-06',\n",
       "       '2022-03-07', '2022-03-08', '2022-03-09', '2022-03-10',\n",
       "       '2022-03-11', '2022-03-12', '2022-03-13', '2022-03-14',\n",
       "       '2022-03-15', '2022-03-16', '2022-03-17', '2022-03-18',\n",
       "       '2022-03-19', '2022-03-20', '2022-03-21', '2022-03-22',\n",
       "       '2022-03-23', '2022-03-24', '2022-03-25', '2022-03-26',\n",
       "       '2022-03-27', '2022-03-28', '2022-03-29', '2022-03-30',\n",
       "       '2022-03-31', '2022-04-01', '2022-04-02', '2022-04-03',\n",
       "       '2022-04-04', '2022-04-05', '2022-04-06', '2022-04-07',\n",
       "       '2022-04-08', '2022-04-09', '2022-04-10', '2022-04-11',\n",
       "       '2022-04-12', '2022-04-13', '2022-04-14', '2022-04-15',\n",
       "       '2022-04-16', '2022-04-17', '2022-04-18', '2022-04-19',\n",
       "       '2022-04-20', '2022-04-21', '2022-04-22', '2022-04-23',\n",
       "       '2022-04-24', '2022-04-25', '2022-04-26', '2022-04-27',\n",
       "       '2022-04-28', '2022-04-29', '2022-04-30', '2022-05-01',\n",
       "       '2022-05-02', '2022-05-03', '2022-05-04', '2022-05-05',\n",
       "       '2022-05-06', '2022-05-07', '2022-05-08', '2022-05-09',\n",
       "       '2022-05-10', '2022-05-11', '2022-05-12', '2022-05-13',\n",
       "       '2022-05-14', '2022-05-15', '2022-05-16', '2022-05-17',\n",
       "       '2022-05-18', '2022-05-19', '2022-05-20', '2022-05-21',\n",
       "       '2022-05-22', '2022-05-23', '2022-05-24', '2022-05-25',\n",
       "       '2022-05-26', '2022-05-27', '2022-05-28', '2022-05-29',\n",
       "       '2022-05-30', '2022-05-31', '2022-06-01', '2022-06-02',\n",
       "       '2022-06-03', '2022-06-04', '2022-06-05', '2022-06-06',\n",
       "       '2022-06-07', '2022-06-08', '2022-06-09', '2022-06-10',\n",
       "       '2022-06-11', '2022-06-12', '2022-06-13', '2022-06-14',\n",
       "       '2022-06-15', '2022-06-16', '2022-06-17', '2022-06-18',\n",
       "       '2022-06-19', '2022-06-20', '2022-06-21', '2022-06-22',\n",
       "       '2022-06-23', '2022-06-24', '2022-06-25', '2022-06-26',\n",
       "       '2022-06-27', '2022-06-28', '2022-06-29', '2022-06-30',\n",
       "       '2022-07-01', '2022-07-02', '2022-07-03', '2022-07-04',\n",
       "       '2022-07-05', '2022-07-06', '2022-07-07', '2022-07-08',\n",
       "       '2022-07-09', '2022-07-10', '2022-07-11', '2022-07-12',\n",
       "       '2022-07-13', '2022-07-14', '2022-07-15', '2022-07-16',\n",
       "       '2022-07-17', '2022-07-18', '2022-07-19', '2022-07-20',\n",
       "       '2022-07-21', '2022-07-22', '2022-07-23', '2022-07-24',\n",
       "       '2022-07-25', '2022-07-26', '2022-07-27', '2022-07-28',\n",
       "       '2022-07-29', '2022-07-30', '2022-07-31', '2022-08-01',\n",
       "       '2022-08-02', '2022-08-03', '2022-08-04', '2022-08-05',\n",
       "       '2022-08-06', '2022-08-07', '2022-08-08', '2022-08-09',\n",
       "       '2022-08-10', '2022-08-11', '2022-08-12', '2022-08-13',\n",
       "       '2022-08-14', '2022-08-15', '2022-08-16', '2022-08-17',\n",
       "       '2022-08-18', '2022-08-19', '2022-08-20', '2022-08-21',\n",
       "       '2022-08-22', '2022-08-23', '2022-08-24', '2022-08-25',\n",
       "       '2022-08-26', '2022-08-27', '2022-08-28', '2022-08-29',\n",
       "       '2022-08-30', '2022-08-31', '2022-09-01', '2022-09-02',\n",
       "       '2022-09-03', '2022-09-04', '2022-09-05', '2022-09-06',\n",
       "       '2022-09-07', '2022-09-08', '2022-09-09', '2022-09-10',\n",
       "       '2022-09-11', '2022-09-12', '2022-09-13', '2022-09-14',\n",
       "       '2022-09-15', '2022-09-16', '2022-09-17', '2022-09-18',\n",
       "       '2022-09-19', '2022-09-20', '2022-09-21', '2022-09-22',\n",
       "       '2022-09-23', '2022-09-24', '2022-09-25', '2022-09-26',\n",
       "       '2022-09-27', '2022-09-28', '2022-09-29', '2022-09-30',\n",
       "       '2022-10-01', '2022-10-02', '2022-10-03', '2022-10-04',\n",
       "       '2022-10-05', '2022-10-06', '2022-10-07', '2022-10-08',\n",
       "       '2022-10-09', '2022-10-10', '2022-10-11', '2022-10-12',\n",
       "       '2022-10-13', '2022-10-14', '2022-10-15', '2022-10-16',\n",
       "       '2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20',\n",
       "       '2022-10-21', '2022-10-22', '2022-10-23', '2022-10-24',\n",
       "       '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28',\n",
       "       '2022-10-29', '2022-10-30'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_total['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46948b4f-b47c-4cb9-87bf-1e5bab326f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('./ML_large_dataframe.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7326cba-9814-4a9e-9e77-566b8bdf2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "#-----------------------------------------------------\n",
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde4e95-b3eb-4c91-97b2-0b2b7b2b4314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
